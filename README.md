
# ğŸ”Š Echo Vision: Voice Navigation for Accessible Web

Echo Vision is a lightweight, browser-based voice navigation system designed to enhance web accessibility for visually impaired users. By using spoken commands such as â€œNavigate Web Pageâ€ or â€œsubmit form,â€ users can interact with websites hands-free.

Developed as a final-year B.Tech project at **Maulana Azad National Urdu University (MANUU), Hyderabad)** under the guidance of **Ms. Tunga Arundhathi (Assistant Professor, CS & IT)**.

---

## ğŸ“Œ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Folder Structure](#-folder-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Supported Voice Commands](#-supported-voice-commands)
- [Testing & Performance](#-testing--performance)
- [Screenshots](#-screenshots)
- [Future Scope](#-future-scope)
- [Team](#-team)
- [License](#-license)

---

## ğŸ“– Overview

Many individuals with visual or motor disabilities face difficulties navigating modern websites. Echo Vision bridges this gap by integrating voice recognition for site-specific navigation using the **Web Speech API**, DOM manipulation, and audio feedback powered by **Python**. It enables hands-free control over web interfaces, making the internet more inclusive.

---

## âœ¨ Features

- ğŸ™ï¸ **Voice-Controlled Navigation** â€“ Issue commands like â€œscroll down,â€ â€œopen feedback,â€ etc.
- âš™ï¸ **Speech-to-Action Mapping** â€“ DOM interactions triggered through JavaScript
- ğŸ”Š **Audio Feedback** â€“ Verbal confirmations via MP3s (played using Python)
- â™¿ **Accessibility-Oriented Design** â€“ Aligned with WCAG 2.1 standards
- ğŸ§© **Modular Architecture** â€“ Designed for integration with screen readers, AI, etc.
- ğŸŒ **Browser Compatibility** â€“ Works with Chrome and Chromium-based browsers

---

## ğŸ› ï¸ Tech Stack

| Layer       | Technology                        |
|------------|------------------------------------|
| Frontend   | HTML, CSS, JavaScript, EJS         |
| Backend    | Node.js + Express                  |
| Voice API  | Web Speech API                     |
| Audio      | Python + gTTS + pydub              |
| Rendering  | EJS Templating                     |
| Testing    | Mocha, Jasmine, Lighthouse         |

---

## ğŸ“ Folder Structure

```
EchoVision/
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ css/               # Styles (index.css)
â”‚   â”œâ”€â”€ js/                # JavaScript (speechToText.js, typed.js)
â”‚   â””â”€â”€ audio/             # MP3 feedback files
â”œâ”€â”€ views/                 # EJS templates (home, about, how-to-use, feedback)
â”œâ”€â”€ scripts/               # Python: visibility-project-python.py
â”œâ”€â”€ app.js                 # Express server
â”œâ”€â”€ package.json
â””â”€â”€ README.md              # You're reading it ğŸ™‚
```

---

## ğŸ§° Installation

### Prerequisites

- Node.js v14 or later
- Python 3.x
- Browser: Chrome / Edge (Chromium-based)

### Clone the Repository

```bash
[git clone https://github.com/Sahil-Ali-01/Echo-Vision-Voice-Navigation-Accessible-Web.git
cd Echo-Vision-Voice-Navigation-Accessible-Web
```

### Install Node Dependencies

```bash
npm install
```

### Install Python Packages

```bash
pip install pydub gTTS beautifulsoup4
```

---

## â–¶ï¸ Usage

### Run the Project

```bash
node app.js
```

Then, open your browser and go to:

```
http://localhost:3000
```

- Double-click on the page to re-trigger the voice system.
- Speak predefined commands into your mic (e.g., â€œscroll downâ€).

---

## ğŸ™ï¸ Supported Voice Commands

| Command              | Action                                 |
|----------------------|----------------------------------------|
| "scroll down"        | Scrolls the webpage down               |
| "scroll up"          | Scrolls the webpage up                 |
| "go to about"        | Navigates to About page                |
| "open feedback"      | Opens the Feedback page                |
| "submit form"        | Submits the active form                |
| "focus input"        | Focuses on the first input field       |
| "stop"               | Stops voice navigation temporarily     |

---

## âœ… Testing & Performance

### âœ… Unit Testing
- Tested voice command handlers using **Jasmine** and **Mocha**

### ğŸ” Manual Testing
- Used in real-world scenarios with visually impaired test users

### ğŸ“Š Accessibility Audit
- Tools: **Google Lighthouse**, **WAVE**
- Score: Passed WCAG 2.1 AA tests

### âš¡ Performance Metrics

| Metric              | Result           |
|---------------------|------------------|
| Average Response    | 300â€“500 ms       |
| Accuracy (Quiet)    | 92%              |
| Accuracy (Noisy)    | 75%              |

---


## ğŸš€ Future Scope

- ğŸ”— Integration with JAWS, NVDA, and TalkBack screen readers
- ğŸ§  AI-based Natural Language Command Interpretation
- ğŸŒ Multilingual voice support
- ğŸ›ï¸ Customizable command profiles per user
- ğŸ”‡ Noise-canceling microphone compatibility

---

## ğŸ‘¨â€ğŸ’» Team

| Name              | Role         |
|-------------------|--------------|
| Sahil Ali         | Developer    |
| Saba Kausher      | Developer    |
| Fariha            | Developer    |

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” feel free to use and adapt.

---

> ğŸ’¡ â€œMaking the web accessible is not just about compliance â€” it's about inclusion.â€
